{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Basic Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "# Preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler \n",
        "\n",
        "# Evaluation\n",
        "from sklearn import linear_model, datasets \n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.model_selection import train_test_split, cross_val_score \n",
        "\n",
        "# Classifier (machine learning algorithm) \n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "# Read data\n",
        "# https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling\n",
        "dataset = pd.read_csv('../input/Churn_Modelling.csv', header = 0)\n",
        "\n",
        "# Tmp data\n",
        "dataset_tmp = dataset.copy()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions\n",
        "\n",
        "Sol1: Test PCA -> Decrease size\n",
        "\n",
        "Sol2: Feature Importance \n",
        "\n",
        "Sol3: Feature Ranking\n",
        "\n",
        "Sol4: Outlier\n"
      ],
      "metadata": {
        "trusted": true,
        "_uuid": "b824c56132e97c261f857b8251aa6a1b0d89bc4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split Train and Test and check shape \n",
        "def SplitDataFrameToTrainAndTest(DataFrame, TrainDataRate, TargetAtt):\n",
        "    # gets a random TrainDataRate % of the entire set\n",
        "    training = DataFrame.sample(frac=TrainDataRate, random_state=1)\n",
        "    # gets the left out portion of the dataset\n",
        "    testing = DataFrame.loc[~DataFrame.index.isin(training.index)]\n",
        "\n",
        "    X_train = training.drop(TargetAtt, 1)\n",
        "    y_train = training[[TargetAtt]]\n",
        "    X_test = testing.drop(TargetAtt, 1)\n",
        "    y_test = testing[[TargetAtt]]\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "    \n",
        "def PrintTrainTestInformation(X_train, y_train, X_test, y_test):\n",
        "    print(\"Train rows and columns : \", X_train.shape)\n",
        "    print(\"Test rows and columns : \", X_test.shape)\n",
        "\n",
        "def DrawJointPlot(DataFrame, XAtt, yAtt, bins = 20):\n",
        "    sns.set(color_codes=True)\n",
        "    sns.distplot(data[XAtt], bins=bins);\n",
        "    df = pd.DataFrame(DataFrame, columns=[XAtt,yAtt])\n",
        "    df = df.reset_index(drop=True)\n",
        "    sns.jointplot(x=XAtt, y=yAtt, data=df)\n",
        "    \n",
        "def DrawBoxplot2(DataFrame, xAtt, yAtt, hAtt=\"N/A\"):\n",
        "    plt.figure()\n",
        "    if(hAtt == \"N/A\"):\n",
        "        sns.boxplot(x=xAtt, y=yAtt,  data=DataFrame)\n",
        "    else:\n",
        "        sns.boxplot(x=xAtt, y=yAtt,  hue=hAtt,  data=DataFrame)\n",
        "    plt.show()\n",
        "    \n",
        "def DrawBarplot(DataFrame, att):\n",
        "    Distribution = DataFrame[att].value_counts()\n",
        "    Distribution = pd.DataFrame({att:Distribution.index, 'Freq':Distribution.values})\n",
        "    Distribution = Distribution.sort_values(by=att, ascending=True)\n",
        "    plt.bar(Distribution[att], Distribution[\"Freq\"])\n",
        "    plt.xticks(Distribution[att])\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title('Barplot of ' + att)\n",
        "    plt.show()   \n",
        "    \n",
        "def DrawCountplot(DataFrame, att, hatt=\"N/A\"):\n",
        "    if(hatt == \"N/A\"):\n",
        "        sns.countplot(x=att, data=DataFrame)\n",
        "    else:\n",
        "        sns.countplot(x=att, hue=hatt, data=DataFrame)\n",
        "    plt.show()\n",
        "    \n",
        "def DrawHistogram(DataFrame, att):\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.figure()\n",
        "    DataFrame[att].hist(edgecolor='black', bins=20)\n",
        "    plt.title(att)\n",
        "    plt.show()\n",
        "    \n",
        "def DetectOutlierByIQR(DataFrame, AttList, Rate = 3.0): #xac dinh diem bat thuong tren tung tieu chi\n",
        "    OutlierIdx = []\n",
        "    for att in AttList:\n",
        "        AttData = DataFrame.loc[:, att]\n",
        "        lowerq = AttData.quantile(0.25)\n",
        "        upperq = AttData.quantile(0.75)\n",
        "        IQR = upperq - lowerq\n",
        "        threshold_upper = (IQR * Rate) + upperq\n",
        "        threshold_lower = lowerq - (IQR * Rate)\n",
        "        AttOutlierIdx = set(AttData[AttData.apply(lambda x: x > threshold_upper\n",
        "                                                    or x < threshold_lower)].index.get_values())\n",
        "        OutlierIdx = set(OutlierIdx) | AttOutlierIdx\n",
        "\n",
        "        # print(\"Min, Max and IQR : %f, %f, and %f\" % (AttData.min(), AttData.max(), IQR))\n",
        "        # print(\"Upper Fence and Lower Fence : %f and %f\" % (threshold_lower, threshold_upper))\n",
        "        # print(\"OutlierIdx : \" + str(OutlierIdx))\n",
        "        # print(att + \" \"  + str(len(AttOutlierIdx)) + \" Outlier Idx : \" + str(AttOutlierIdx))\n",
        "\n",
        "    OutlierIdx = list(OutlierIdx)\n",
        "    OutlierIdx = sorted(OutlierIdx)\n",
        "    return OutlierIdx\n",
        "      \n",
        "def DetectOutlierByLOF(DataFrame, AttList, LOFThresh=3.0, neighbors = 10): #xac dinh diem bat thuong tren nhom tieu chi\n",
        "        import numpy as np\n",
        "        from sklearn.neighbors import LocalOutlierFactor\n",
        "\n",
        "        clf = LocalOutlierFactor(n_neighbors=neighbors)\n",
        "        AttData = DataFrame.loc[:, AttList].values\n",
        "        y_pred = clf.fit_predict(AttData)\n",
        "        AttData_scores = -1 * clf.negative_outlier_factor_\n",
        "        LOFFactorData = pd.DataFrame(AttData_scores, columns=['LOF'])\n",
        "        LOFFactorData = LOFFactorData.sort_values('LOF', ascending=False)\n",
        "        LOFFactorData = LOFFactorData.reset_index(drop=False)\n",
        "        # print(LOFFactorData.loc[0:10, :])\n",
        "        OutlierThreshold = LOFThresh\n",
        "        SuspectOutlierData = LOFFactorData[LOFFactorData['LOF'].apply(lambda x: x >\n",
        "                                                                    OutlierThreshold)]\n",
        "        OutlierIdx = SuspectOutlierData.loc[:, 'index'].tolist()\n",
        "        # print(\"OutlierIdx : \" + str(OutlierIdx))\n",
        "\n",
        "        return OutlierIdx, LOFFactorData\n",
        "      \n",
        "def RemoveRowsFromDataFrame(DataFrame, RowIdxList = []):\n",
        "        DataFrame = DataFrame.drop(RowIdxList)\n",
        "        DataFrame = DataFrame.reset_index(drop=True)\n",
        "        return DataFrame\n",
        "\n",
        "def NaiveBayesLearning(DataTrain, TargetTrain):\n",
        "    from sklearn.naive_bayes import GaussianNB\n",
        "    NBModel = GaussianNB()\n",
        "    NBModel.fit(DataTrain, TargetTrain.values.ravel())\n",
        "\n",
        "    return NBModel\n",
        "\n",
        "def NaiveBayesTesting(NBModel,DataTest, TargetTest):\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    PredictTest = NBModel.predict(DataTest)\n",
        "    Accuracy = accuracy_score(TargetTest, PredictTest)\n",
        "\n",
        "    return Accuracy, PredictTest\n",
        "\n",
        "def LogisticRegressionLearning(DataTrain, TargetTrain):\n",
        "    # Apply the Logistic Regression\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    from sklearn import metrics\n",
        "    logreg = LogisticRegression()\n",
        "    # training by Logistic Regression\n",
        "    logreg.fit(DataTrain, TargetTrain.values.ravel())\n",
        "\n",
        "    return logreg\n",
        "\n",
        "def LogisticRegressionTesting(LRModel,DataTest, TargetTest):\n",
        "    # Testing and calculate the accuracy\n",
        "    from sklearn.metrics import accuracy_score\n",
        "\n",
        "    logreg = LRModel\n",
        "    PredictTest = logreg.predict(DataTest)\n",
        "    Accuracy = accuracy_score(TargetTest, PredictTest)\n",
        "    # print('Logistic regression accuracy: {:.3f}'.format(Accuracy))\n",
        "\n",
        "    return Accuracy, PredictTest\n",
        "\n",
        "def RandomForestLearning(DataTrain, TargetTrain):\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "    rf = RandomForestClassifier()\n",
        "    rf.fit(DataTrain, TargetTrain.values.ravel())\n",
        "\n",
        "    return rf\n",
        "\n",
        "def RandomForestTesting(RFModel,DataTest, TargetTest):\n",
        "    from sklearn.metrics import accuracy_score\n",
        "\n",
        "    PredictTest = RFModel.predict(DataTest)\n",
        "    Accuracy = accuracy_score(TargetTest, PredictTest)\n",
        "    # print('Random Forest Accuracy: {:.3f}'.format(accuracy_score(TargetTest, PredictTest)))\n",
        "\n",
        "    return Accuracy, PredictTest\n",
        "\n",
        "def SVMLearning(DataTrain, TargetTrain, ClassifierType = \" \"):\n",
        "    from sklearn.svm import SVC\n",
        "    if(ClassifierType == 'Linear'):\n",
        "        svc = SVC(kernel=\"linear\", C=0.025)\n",
        "#         print('SVM Linear processing')\n",
        "    # Radial basis function kernel\n",
        "    elif (ClassifierType == 'RBF'):\n",
        "        svc = SVC(gamma=2, C=1)\n",
        "#         print('SVM RBF processing')\n",
        "    else:\n",
        "        svc = SVC()\n",
        "#         print('SVM Default processing')\n",
        "    svc.fit(DataTrain, TargetTrain.values.ravel())\n",
        "    return svc\n",
        "\n",
        "def SVMTesting(SVMModel, DataTest, TargetTest):\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    PredictTest = SVMModel.predict(DataTest)\n",
        "    Accuracy = accuracy_score(TargetTest, PredictTest)\n",
        "    # print('Support Vector Machine Accuracy: {:.3f}'.format(accuracy_score(TargetTest, PredictTest)))\n",
        "    return Accuracy, PredictTest\n",
        "\n",
        "def KNNLearning(DataTrain, TargetTrain, K = 3):\n",
        "    from sklearn.neighbors import KNeighborsClassifier\n",
        "    neigh = KNeighborsClassifier(n_neighbors=K)\n",
        "    neigh.fit(DataTrain, TargetTrain.values.ravel())\n",
        "\n",
        "    return neigh\n",
        "\n",
        "def KNNTesting(KNNModel,DataTest, TargetTest):\n",
        "    from sklearn.metrics import accuracy_score\n",
        "\n",
        "    PredictTest = KNNModel.predict(DataTest)\n",
        "    Accuracy = accuracy_score(TargetTest, PredictTest)\n",
        "    # print('KNN Accuracy: {:.3f}'.format(accuracy_score(TargetTest, PredictTest)))\n",
        "\n",
        "    return Accuracy, PredictTest\n",
        "\n",
        "def ANNLearning(DataTrain, TargetTrain):\n",
        "    from sklearn.neural_network import MLPClassifier\n",
        "    ANNModel = MLPClassifier(alpha=1)\n",
        "    ANNModel.fit(DataTrain, TargetTrain.values.ravel())\n",
        "    return ANNModel\n",
        "\n",
        "def ANNTesting (ANNModel, DataTest, TargetTest):\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    PredictTest = ANNModel.predict(DataTest)\n",
        "    Accuracy = accuracy_score(TargetTest, PredictTest)\n",
        "    # print('Neural Net Accuracy: {:.3f}'.format(Accuracy))\n",
        "    return Accuracy, PredictTest\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "_uuid": "aac9ab3647f908d8cdbec972292be55222b0dd6e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking missing values\n",
        "\n- Fill missing value: Median / Mode, Label Encode / Dummies"
      ],
      "metadata": {
        "_uuid": "7e7dfaa9342954a93f8798d83d4c3d5e7540ade8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the percentage of missing values in each variable\n",
        "(dataset.isnull().sum()/len(dataset)*100)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "_uuid": "151176af8c354e451952c7085031aaff6c0633f2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "_uuid": "479d9687af231bc925b1afe28a93c84e58279594"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "0.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}